Reporte Final: Fine-tuning Microsoft Phi-2 para Tutor√≠a Matem√°tica
üìã Resumen Ejecutivo
Este proyecto implement√≥ y evalu√≥ diferentes estrategias de fine-tuning del modelo Microsoft Phi-2 (2.7B par√°metros) para crear un tutor matem√°tico especializado. Se realizaron m√∫ltiples iteraciones experimentales que revelaron la importancia cr√≠tica de la configuraci√≥n de hiperpar√°metros y el impacto del sobreentrenamiento en modelos matem√°ticos.
Imagen 1 - Especificaciones del Hardware Utilizado
üõ†Ô∏è Metodolog√≠a
Herramientas y Tecnolog√≠as

Modelo Base: Microsoft Phi-2 (2.7B par√°metros)
Hardware: NVIDIA GeForce GTX 1050 Ti (4GB VRAM)
T√©cnica: LoRA (Low-Rank Adaptation) para entrenamiento eficiente
Dataset: 90+ ejemplos de operaciones matem√°ticas b√°sicas y conceptos num√©ricos
Framework: PyTorch + Transformers + PEFT

Imagen 2 - Estructura del Proyecto de Fine-tuning
Configuraciones Experimentales
Se evaluaron tres configuraciones principales de learning rate para analizar su impacto en el rendimiento:
Configuraci√≥nLearning Rate√âpocasTiempoComportamientoSobreentrenado1e-425032.5 horasAlucinaciones severasOptimizado1e-61.8849 minutosErrores de c√°lculoDestructivo0.5N/AN/AError CUDA - Modelo inutilizable
üìä Resultados Principales
Comparativa de Rendimiento
M√©tricaEntrenamiento ExtensivoEntrenamiento OptimizadoMejoraTiempo32.5 horas49 minutos97.5% reducci√≥n√âpocas2501.88133x menosFLOPS100.8M GF1.16M GF98.8% reducci√≥nP√©rdida0.24023.7851M√°s saludable
Imagen 3 - Resultados del Entrenamiento Inicial (250 √©pocas)
Imagen 4 - An√°lisis de Fases de Entrenamiento y M√©tricas Combinadas
Imagen 5 - Resultados del Entrenamiento Optimizado (2 √©pocas)
Evaluaci√≥n Funcional
Imagen 6 - Modelo con Learning Rate Extremo (0.5) - Error CUDA
Modelo Sobreentrenado (250 √©pocas):

Respuesta a "4+4": Texto incoherente sobre conjuntos num√©ricos y constantes matem√°ticas
Resultado: Alucinaciones extremas, respuestas inutilizables

Imagen 7 - Ejemplos de C√≥digo Python y Respuestas del Modelo
Modelo Optimizado (1.88 √©pocas):

Respuesta a "4+4": "9" (incorrecto pero coherente)
Resultado: Errores de c√°lculo pero sin alucinaciones

Imagen 8 - Interfaz del Evaluador con Respuestas Extensas
Imagen 9 - Pruebas de Operaciones Matem√°ticas B√°sicas
Imagen 10 - Respuestas del Modelo a Operaciones con Orden de Precedencia
Imagen 11 - Modelo Funcionando Correctamente con Respuestas Precisas
Modelo Base sin Fine-tuning:

Precisi√≥n: 60% en operaciones b√°sicas
Resultado: Superior a cualquier versi√≥n entrenada

üîç An√°lisis de Impacto del Learning Rate
Rangos de Comportamiento Identificados
Learning RateComportamientoAplicaci√≥n5e-6 a 1e-5Respuestas estables y correctasRango √≥ptimo1e-4 a 1e-3Errores ocasionales a alucinacionesZona de riesgo1e-2 a 0.1Alucinaciones controladasExperimentaci√≥n0.5+Crashes CUDADestructivo
Hallazgo Cr√≠tico: Gradientes Explosivos
La configuraci√≥n con learning rate 0.5 provoc√≥ errores a nivel de hardware (CUDA device-side assert), demostrando que hiperpar√°metros extremos pueden corromper completamente el modelo.
üí° Conclusiones y Lecciones Aprendidas
1. Sobreentrenamiento vs. Generalizaci√≥n

250 √©pocas: Memorizaci√≥n excesiva (loss=0.2402) resultando en alucinaciones
2 √©pocas: Mejor generalizaci√≥n (loss=3.7851) con errores controlados

2. Eficiencia Computacional

Reducir √©pocas de 250 a 2 mejor√≥ la eficiencia en 97.5% sin sacrificar utilidad
El 96% del aprendizaje √∫til ocurre en las primeras 50 √©pocas

3. Preservaci√≥n de Conocimiento

El modelo base supera al fine-tuning en operaciones b√°sicas
Fine-tuning puede deteriorar capacidades preexistentes del modelo

4. Configuraci√≥n √ìptima Identificada
pythonLEARNING_RATE = 1e-5    # Equilibrio estabilidad-aprendizaje
NUM_EPOCHS = 2          # Evita sobreentrenamiento
LORA_R = 4              # Par√°metros conservadores
LORA_ALPHA = 8          # Configuraci√≥n estable
üöÄ Recomendaciones
Para Futuros Proyectos de Fine-tuning Matem√°tico:

Usar el modelo base directamente para operaciones b√°sicas con prompting optimizado
Implementar early stopping basado en evaluaci√≥n matem√°tica continua
Aplicar fine-tuning gradual comenzando con conceptos b√°sicos
Priorizar calidad sobre cantidad en datos de entrenamiento

Para Optimizaci√≥n de Recursos:

Configuraciones conservadoras (learning rate ‚â§ 1e-5) son m√°s efectivas
Pocas √©pocas (1-3) suficientes para la mayor√≠a de casos
Monitoreo en tiempo real de respuestas matem√°ticas durante entrenamiento

üìà Impacto del Proyecto
Este estudio demuestra que en fine-tuning de modelos matem√°ticos, "menos es m√°s": configuraciones conservadoras y entrenamientos cortos producen mejores resultados que entrenamientos extensivos. La reducci√≥n del 97.5% en tiempo computacional mientras se mantiene funcionalidad representa un enfoque m√°s sostenible y accesible para el desarrollo de modelos especializados.
El hallazgo de que el modelo base supera al fine-tuning especializado en matem√°ticas b√°sicas sugiere una reevaluaci√≥n de estrategias, priorizando la preservaci√≥n de conocimiento preentrenado sobre la especializaci√≥n extensiva.

Proyecto desarrollado como estudio de caso en optimizaci√≥n de hiperpar√°metros y t√©cnicas de fine-tuning eficiente.